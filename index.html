<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TriTex: Learning Texture from a Single Mesh via Triplane Semantic Features</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KBKFF5WPJF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-KBKFF5WPJF');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <style>
    /* General Styles */
    /* General Styles */
    body {
      font-family: 'Google Sans', Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #ffffff;
      color: #000000;
    }

    .subtitle {
      color: #000000;
      margin-top: 0;
    }

    h1.title.is-1,
    h2.title.is-3 {
      text-align: center;
      margin: 20px 0;
      color: #363636;
    }

    /* Section and Content Styles */
    section {
      padding: 20px;
    }

    p {
      line-height: 1.6;
    }

    /* Link Blocks */
    .publication-links .link-block {
      display: block;
      margin-bottom: 10px;
    }

    /* Media Container Styles */
    .hero img,
    .video-container img {
      max-width: 100%;
      height: auto;
    }

    /* Carousel Styles */
    .carousel {
      display: flex;
      gap: 15px;
      overflow-x: auto;
      scroll-snap-type: x mandatory;
      padding: 10px 0;
    }

    .carousel .item {
      scroll-snap-align: start;
      flex: 0 0 auto;
      width: 90%;
      max-width: 320px;
      margin: auto;
    }

    .carousel .item video,
    .carousel .item img {
      border-radius: 8px;
      max-width: 100%;
      height: auto;
      display: block;
    }

    /* Preview Results Section */
    .preview-results-container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
    }

    .preview-results-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 20px;
      justify-content: center;
      max-width: 800px;
      margin: 0 auto;
    }

    .preview-item {
      border: 1px solid #e0e0e0;
      border-radius: 12px;
      padding: 10px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      background: #fff;
      max-width: 350px;
      margin: 0 auto;
    }

    .preview-item video {
      width: 100%;
      height: auto;
      max-height: 300px;
      object-fit: contain;
      border-radius: 8px;
    }

    .preview-caption {
      margin-top: 10px;
      font-size: 1rem;
      text-align: center;
      color: #4a4a4a;
      background: #f8f9fa;
      padding: 5px 10px;
      border-radius: 6px;
      border: 1px solid #eee;
    }

    /* Editing Grid Styles */
    .editing-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 20px;
      justify-content: center;
    }

    .edit-item {
      border: 1px solid #e0e0e0;
      border-radius: 12px;
      padding: 10px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      background: #fff;
    }

    .edit-item video {
      width: 100%;
      height: auto;
      border-radius: 8px;
    }

.prompt {
  display: flex;
  justify-content: center;
  flex-wrap: nowrap; /* Prevent wrapping */
  gap: 10px; /* Space between items */
  margin-top: 10px;
  font-size: 1rem;
  text-align: center;
  color: #4a4a4a;
  background: #f8f9fa;
  padding: 5px 10px;
  border-radius: 6px;
  border: 1px solid #eee;
  }

  .prompt span {
    white-space: nowrap; /* Prevent text from wrapping */
  }

  /* Remove this rule that's causing the issue */
  .prompt span:first-child {
    margin-right: 0; /* Remove the margin-right: 2em that's causing problems */
  }

  /* Add this for more explicit control in mobile view */
  @media (max-width: 768px) {
    .prompt {
      padding: 5px;
    }
    
    /* Make sure spacing between items is controlled by gap */
    .prompt span:first-child {
      margin-right: 0;
    }
  }

    /* Editing Block Styles */
    .editing-block {
      margin-bottom: 40px;
      text-align: center;
    }

    .editing-block .title.is-4 {
      margin-bottom: 20px;
      font-size: 1.5rem;
      color: #4a4a4a;
    }

    .content h3.title.is-5 {
      color: #363636;
    }


    /* Method Section Styles */
    .method-section {
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: left;
      margin: 20px auto;
      max-width: 1000px;
      padding: 20px;
    }

    .method-section img {
      max-width: 100%;
      height: auto;
      margin-bottom: 20px;
      border: 1px solid #ddd;
      border-radius: 8px;
    }

    .method-section ul {
      list-style: disc;
      padding: 0 20px;
      line-height: 1.8;
    }

    .method-section li {
      margin-bottom: 10px;
    }

    /* Footer Styles */
    .footer {
      background: #f8f9fa;
      text-align: center;
      padding: 20px;
    }

    .footer a {
      color: #3273dc;
    }

    /* Transform Arrow Style */
    .transform-arrow {
      display: inline-block;
      margin: 0 5px;
    }

    /* Responsive Design */
    @media (min-width: 768px) {
      .publication-links .link-block {
        margin-bottom: 0;
        display: inline-block;
      }
    }

    @media (max-width: 768px) {
      h1.title.is-1 {
        font-size: 1.8rem;
      }

      h2.title.is-3 {
        font-size: 1.5rem;
      }

      .carousel .item {
        width: 100%;
        max-width: 280px;
      }

      .editing-grid {
        grid-template-columns: 1fr;
      }

      .method-section {
        padding: 10px;
      }

      .method-section ul {
        padding: 0 10px;
      }

      .preview-results-grid {
        grid-template-columns: 1fr;
        max-width: 400px;
      }

      .preview-item {
        max-width: 100%;
      }

      .preview-item video {
        max-height: 250px;
      }

      .publication-links .link-block {
        margin-bottom: 20px;
      }
    }

    @media (max-width: 480px) {
      .carousel .item {
        width: 100%;
      }

      .footer {
        font-size: 0.9rem;
      }
    }
  </style>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TriTex: Learning Texture from a Single Mesh via Triplane Semantic Features</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.co.il/citations?hl=en&user=pP2DcRQAAAAJ">Dana
                  Cohen-Bar</a><sup>1,2</sup>&nbsp &nbsp
              </span>
              <span class="author-block">
                <a href="https://scholar.google.ca/citations?user=fAxws1sAAAAJ&hl=en">Daniel
                  Cohen-Or</a><sup>1</sup>&nbsp &nbsp
              </span>
              <span class="author-block">
                <a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a><sup>2</sup>&nbsp
                &nbsp
              </span>
              <span class="author-block">
                <a href="https://scholar.google.co.il/citations?user=kc4-e8oAAAAJ&hl=en&oi=ao">Yoni
                  Kasten</a><sup>2</sup>&nbsp &nbsp
              </span>

            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tel-Aviv University</span>

              <span class="author-block"><sup>2</sup>NVIDIA</span> &nbsp &nbsp
            </div>

            <div>
              <p style="font-size:23px;font-weight:bold;padding-top: 5px;">CVPR 2025</p>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.16630" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/DanaCohen95/TriTex"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code - Coming Soon!</span>
                  </a>
                </span>
              </div>
            </div>
            <div class="is-size-5 publication-authors">
            </div>
          </div>
        </div>

        <h2 class="subtitle has-text-centered">
          TriTex is a method for semantic-aware texture transfer between meshes. It levereges a pretrained feature
          extractor to train on a single example and generalize at test time to a novel target mesh.</h2>

        <div class="image-container">
          <img src="static/images/teaser.jpg" alt="Teaser" style="width:100%;">
        </div>
      </div>
    </div>

    <section class="section hero is-light is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p style="line-height: 1.8; font-size: 1.0rem;">
                As 3D content creation continues to grow, transferring semantic textures between 3D meshes remains a
                significant
                challenge in computer graphics. While recent methods leverage text-to-image diffusion models for
                texturing, they often
                struggle to preserve the appearance of the source texture during texture transfer. We present TriTex, a
                novel approach
                that learns a volumetric texture field from a single textured mesh by mapping semantic features to
                surface colors. Using
                an efficient triplane-based architecture, our method enables semantic-aware texture transfer to a novel
                target mesh.
                Despite training on just one example, it generalizes effectively to diverse shapes within the same
                category. Extensive
                evaluation on our newly created benchmark dataset shows that TriTex achieves superior texture transfer
                quality and fast
                inference times compared to existing methods. Our approach advances single-example texture transfer,
                providing a
                practical solution for maintaining visual coherence across related 3D models in applications like game
                development and
                simulation.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-small is-centered">
      <div class="container is-fluid is-centered has-text-centered">

        <h1 class="title is-3" style="color:black">Results</h1>
        <div class="editing-container">
          <div class="editing-grid">
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/goldfish.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/ship.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/car.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/bird.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/dog.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/dragon.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/fish.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/guitar.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
            <div class="edit-item">
              <video autoplay muted loop playsinline>
                <source src="static/videos/teaser_fish.mp4" type="video/mp4">
              </video>
              <p class="prompt"><span>source shape</span><span>target shape</span></p>
            </div>
              <div class="edit-item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/vase.mp4" type="video/mp4">
                </video>
                <p class="prompt"><span>source shape</span><span>target shape</span></p>
              </div>
              <div class="edit-item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/tiger.mp4" type="video/mp4">
                </video>
                <p class="prompt"><span>source shape</span><span>target shape</span></p>
              </div>
              <div class="edit-item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/mickey.mp4" type="video/mp4">
                </video>
                <p class="prompt"><span>source shape</span><span>target shape</span></p>
              </div>
          </div>
        </div>
      </div>
    </section>


    <section class="section hero is-small is-centered is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Method</h2>
            <div class="image-container">
              <img src="static/images/method.jpg" alt="Method fig" style="width:100%;">
            </div>
            <div class="content has-text-justified is-centered" style="margin-top: 1.5rem;">
              <!-- Training Pipeline -->
              <h3 class="title is-5">Training Pipeline</h3>
              <ul class="column is-centered has-text-justified">
                <li>
                  Given an input textured mesh and its pre-extracted Diff3F features, we project six orthographic views
                  to
                  create an initial triplane.
                </li>
                <li>
                  This triplane is processed using triplane-aware convolutional blocks, which, along with the texture
                  MLP,
                  define a
                  coloring neural field. This field, together with the input geometry, is used to render the colored
                  mesh.
                </li>
                <li>
                  Appearance losses are applied between the true mesh appearance and the rendered appearance.
                </li>
              </ul>

              <!-- Inference Pipeline -->
              <h3 class="title is-5">Inference Pipeline</h3>
              <ul class="column is-centered has-text-justified">
                <li>
                  Given a new mesh (left), our pre-trained model maps its semantic properties to colors
                  (right), transferring the texture from the original textured mesh learned during the training phase.
                </li>
                <li>
                  The output maintains the style and appearance characteristics learned during the training process
                  while
                  applying them to the new geometry.
                </li>
              </ul>
            </div>
          </div>
    </section>

    <script>
      document.addEventListener('DOMContentLoaded', function () {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
          video.play().catch(function (error) {
            console.log("Video autoplay failed:", error);
          });
        });
      });
    </script>
    <script>
      document.addEventListener('DOMContentLoaded', function () {
        bulmaCarousel.attach('#results-carousel', {
          slidesToShow: 5, // Default slides visible
          slidesToScroll: 1,
          infinite: true,
          navigation: true,
          pagination: false,
          breakpoints: [
            {
              changePoint: 768,
              slidesToShow: 2,
              slidesToScroll: 1
            },
            {
              changePoint: 1024,
              slidesToShow: 3,
              slidesToScroll: 1
            },
            {
              changePoint: 1216,
              slidesToShow: 4,
              slidesToScroll: 1
            },
            {
              changePoint: 1408,
              slidesToShow: 5,
              slidesToScroll: 1
            }
          ]
        });
      });
    </script>

      <!-- BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{cohenbar2025tritexlearningtexturesingle,
      title={TriTex: Learning Texture from a Single Mesh via Triplane Semantic Features},
      author={Dana Cohen-Bar and Daniel Cohen-Or and Gal Chechik and Yoni Kasten},
      year={2025},
      eprint={2503.16630},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2503.16630},
      }</code></pre>
    </div>
</section>
  <!-- End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the&nbsp;<a href="https://nerfies.github.io/" target="_blank">Nerfies</a>&nbsp;project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>


</body>

</html>